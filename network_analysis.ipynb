{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <a id='toc1_'></a>[Part 1. Notebook for Network and Topological Analysis in Neuroscience](#toc0_)\n",
    "\n",
    "Authors: Isaac Sebenius (Inspired heavily from the work by Eduarda Centeno & Fernando Santos), see [Acknowledgements](#acknowledgements) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Table of contents**<a id='toc0_'></a>    \n",
    "- [Part 1. Notebook for Network and Topological Analysis in Neuroscience](#toc1_)    \n",
    "    - [ **1.** Imports](#toc1_1_1_)    \n",
    "      - [Let's start with the necessary packages for the following computations:](#toc1_1_1_1_)    \n",
    "    - [**2.** Importing data & exploring connectivity matrices](#toc1_1_2_)    \n",
    "      - [Now we will start working with the brain data.](#toc1_1_2_1_)    \n",
    "        - [**Let's look at what these group-averaged networks look like, using a standard heatmap!**](#toc1_1_2_1_1_)    \n",
    "    - [How do these networks relate to each other? What do you expect the correlation between these networks to be?](#toc1_1_3_)    \n",
    "    - [ What's the takeaway here? What are other ways we could go about studying the relationship between structure and function in the brain?](#toc1_1_4_)    \n",
    "        - [**Key point:**](#toc1_1_4_1_1_)    \n",
    "        - [**Key point:**](#toc1_1_4_1_2_)    \n",
    "    - [**3.**  Graph Theory](#toc1_1_5_)    \n",
    "      - [From now, we will start working with some standard Graph Theory metrics.](#toc1_1_5_1_)    \n",
    "        - [**Key point:**](#toc1_1_5_1_1_)    \n",
    "        - [We will start by creating the graph and removing its self-loops (i.e., a connection of a node with itself). For illustrative purposes, we will focus on the group-level fMRI conenctivity graph.](#toc1_1_5_1_2_)    \n",
    "        - [Now, we compute the network's density.](#toc1_1_5_1_3_)    \n",
    "        - [Now, we compute the nodal degree/strength.](#toc1_1_5_1_4_)    \n",
    "        - [Next, we will compute the centralities!](#toc1_1_5_1_5_)    \n",
    "        - [Now, let's move on to the Path Length!](#toc1_1_5_1_6_)    \n",
    "- [Now, go back and redo this past section using graphs at different levels of sparsity. How do the results change?](#toc2_)    \n",
    "- [Explore the relationships between differnet node-level graph features. How do they compare to each other? What might this tell us?](#toc3_)    \n",
    "        - [Now, modularity, assortativity, clustering coefficient and the minimum spanning tree!](#toc3_1_1_1_1_)    \n",
    "      - [Data Visualisation & Graph Theory](#toc3_1_1_2_)    \n",
    "- [Obviously that is WAY too much information. Let's visualise the Minimum Spanning Tree instead.](#toc4_)    \n",
    "  - [**4.** Have some fun with data analysis of brain networks!!](#toc4_1_)    \n",
    "  - [**5.** References](#toc4_2_)    \n",
    "  - [**6.** Acknowledgements](#toc4_3_)    \n",
    "\n",
    "<!-- vscode-jupyter-toc-config\n",
    "\tnumbering=false\n",
    "\tanchor=true\n",
    "\tflat=false\n",
    "\tminLevel=1\n",
    "\tmaxLevel=6\n",
    "\t/vscode-jupyter-toc-config -->\n",
    "<!-- THIS CELL WILL BE REPLACED ON TOC UPDATE. DO NOT WRITE YOUR TEXT IN THIS CELL -->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='imports'></a>\n",
    "### <a id='toc1_1_1_'></a>[ **1.** Imports](#toc0_)\n",
    "#### <a id='toc1_1_1_1_'></a>[Let's start with the necessary packages for the following computations:](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "V3O2seQhpdlJ"
   },
   "outputs": [],
   "source": [
    "# Basic data manipulation and visualisation libraries\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "from scipy import stats\n",
    "\n",
    "# Network Libraries\n",
    "import networkx as nx\n",
    "\n",
    "# CANNOT CONDA INSTALL BELOW?\n",
    "from nxviz import CircosPlot, circos\n",
    "import community\n",
    "\n",
    "\n",
    "# Magic command to change plotting backend\n",
    "#%matplotlib qt\n",
    "\n",
    "# Magic command to load watermark\n",
    "#%load_ext watermark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Possibility to stop warnings\n",
    "#import warnings\n",
    "#warnings.filterwarnings('ignore') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='importing-data'></a>\n",
    "### <a id='toc1_1_2_'></a>[**2.** Importing data & exploring connectivity matrices](#toc0_)\n",
    "#### <a id='toc1_1_2_1_'></a>[Now we will start working with the brain data.](#toc0_)\n",
    "Here, we will try to cover both computation and some theoretical background/key points on each section. \n",
    "Our first step will be on how to import the matrix data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import os\n",
    "os.chdir('/imaging/henson/users/rh01/Methods/Cognestic-Stats/CognesticNetworks')\n",
    "\n",
    "#Load individual data for 100 subjects from the HCP dataset\n",
    "fmri_connectivity = pickle.load(open('Simplified/FCs.HCP.pkl','rb'))\n",
    "mind_connectivity = pickle.load(open('Simplified/MIND.HCP.pkl','rb'))\n",
    "dti_connectivity = pickle.load(open('Simplified/DTI.HCP.pkl','rb'))\n",
    "\n",
    "mask = np.ones(fmri_connectivity[0].shape)\n",
    "mask[np.diag_indices(360)] = np.nan\n",
    "\n",
    "#Compute group-averaged networks \n",
    "mean_fmri_connectivity = np.mean(fmri_connectivity, axis = 0)*mask\n",
    "mean_mind_connectivity = np.mean(mind_connectivity, axis = 0)*mask\n",
    "mean_dti_connectivity = np.mean(dti_connectivity, axis = 0)*mask\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "region_information = pd.read_csv('HCP-coordinates.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtaining name of areas according to matching file\n",
    "lineList = list(region_information['regionName'].values.flatten())\n",
    "\n",
    "# Obtaining a random list of numbers to simulate subnetworks -- THESE NUMBERS DO NOT CORRESPOND TO ANY REAL CLASSIFICATION\n",
    "sublist = np.array(np.loadtxt('HCP_Yeo_symmetric.txt'))\n",
    "\n",
    "cmap_dict = dict(zip(list(range(8)), sns.color_palette(\"tab10\", n_colors = 8)))\n",
    "# Obtaining a random list of colors that will match the random subnetwork classification for further graphs -- THESE COLORNAMES DO NOT CORRESPOND TO ANY REAL CLASSIFICATION\n",
    "colorlist = np.array([cmap_dict[x] for x in sublist])\n",
    "\n",
    "# Obtaining a random list of colors (in numbers) that will match the random subnetwork classification for further graphs -- THESE NUMBERS DO NOT CORRESPOND TO ANY REAL CLASSIFICATION\n",
    "colornumbs = np.array(colorlist.copy())#np.genfromtxt('./subnet_colors_number.txt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##################################################################################################\n",
    "##### <a id='toc1_1_2_1_1_'></a>[**Let's look at what these group-averaged networks look like, using a standard heatmap!**](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 3, figsize = (15, 5))\n",
    "\n",
    "sns.heatmap(mean_fmri_connectivity, ax = ax[0], square = True, cbar_kws = {\"shrink\": 0.75})\n",
    "sns.heatmap(mean_mind_connectivity, ax = ax[1], square = True, cbar_kws = {\"shrink\": 0.75})\n",
    "sns.heatmap(mean_dti_connectivity, ax = ax[2], square = True, cbar_kws = {\"shrink\": 0.75})\n",
    "\n",
    "ax[0].set_title('Mean Functional Connectivity')\n",
    "ax[1].set_title('Mean DTI Connectivity')\n",
    "ax[2].set_title('Mean MIND Connectivity')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##################################################################################################\n",
    "\n",
    "### <a id='toc1_1_3_'></a>[How do these networks relate to each other? What do you expect the correlation between these networks to be?](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('DTI - Functional connectivity edgewise correlation:', str(round(stats.pearsonr(mean_fmri_connectivity[np.triu_indices(360, k = 1)], mean_dti_connectivity[np.triu_indices(360, k = 1)])[0], 2)))\n",
    "print('MIND - Functional conenctivity edgewise correlation:', str(round(stats.pearsonr(mean_fmri_connectivity[np.triu_indices(360, k = 1)], mean_mind_connectivity[np.triu_indices(360, k = 1)])[0], 2)))\n",
    "print('DTI - MIND edgewise correlation:', str(round(stats.pearsonr(mean_mind_connectivity[np.triu_indices(360, k = 1)], mean_dti_connectivity[np.triu_indices(360, k = 1)])[0], 2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a id='toc1_1_4_'></a>[ What's the takeaway here? What are other ways we could go about studying the relationship between structure and function in the brain?](#toc0_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##################################################################################################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### <a id='toc1_1_4_1_1_'></a>[**Key point:**](#toc0_)\n",
    "When working with network analysis in brain data, a couple of crucial decisions have to be made.\n",
    "For example, one can decide to use all network connections - including low-weight links (sometimes considered spurious connections), or establish an arbitrary threshold and keep only links above a specific correlation value. This step can be done in different ways, based solely on the correlation threshold (as done here), or based on network density (i.e., you keep only the 20% strongest correlations). \n",
    "If using an arbitrary threshold, it is also possible to define if the resulting matrix will be weighted (i.e., keeping the edges' weight), or unweighted (binarised matrices).\n",
    "\n",
    "Another point of discussion is how to deal with negative weights in weighted networks. Here, we have chosen to proceed by thresholding for  the top weighted connections, ignoring negative/low connections.\n",
    "\n",
    "*We strongly suggest Reference [3] for a deeper understanding on all these decisions.*\n",
    "\n",
    "Figure 1 provides a schematic summary of the types of networks:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![matrices.jpg](attachment:matrices.jpg)\n",
    "\n",
    "Figure 1. Types of networks. (A) A binary directed graph. (B) Binary, undirected graph. In binary graphs, the presence of a connection is signified by a 1 or 0 otherwise. (C) A representation of graph F as a network of brain areas. (D) A weighted, directed graph. (F) A weighted, undirected graph. In a weighted graph, the strength of the connections is represented by a number [0,1]. (G) A connectivity matrix of C and F. Source: Part of the image was obtained from [Smart Servier Medical Art](https://smart.servier.com/)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### <a id='toc1_1_4_1_2_'></a>[**Key point:**](#toc0_)\n",
    "When working with fMRI brain network data, it is useful to generate some plots (e.g., the heatmaps above for matrix visualisation, and distribution plots of edge weights) to facilitate data comprehension and flag potential artefacts. In brain networks, we expect mostly weak edges and a smaller proportion of strong ones. Is that what we see?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Weight distribution plot\n",
    "\n",
    "def MinMax(X):\n",
    "    X_scaled = (X - X.min(axis=0)) / (X.max(axis=0) - X.min(axis=0))\n",
    "    #X_scaled = X_std * (max - min) + min\n",
    "    return X_scaled\n",
    "\n",
    "centiled_fmri_edges = MinMax(mean_fmri_connectivity[np.triu_indices(360, k =1)])\n",
    "centiled_dti_edges = MinMax(mean_dti_connectivity[np.triu_indices(360, k =1)])\n",
    "centiled_mind_edges = MinMax(mean_mind_connectivity[np.triu_indices(360, k =1)])\n",
    "\n",
    "fig, ax = plt.subplots(1, 3, figsize = (15, 5))\n",
    "\n",
    "sns.histplot(centiled_fmri_edges, ax = ax[0])\n",
    "sns.histplot(centiled_mind_edges, ax = ax[1])\n",
    "sns.histplot(centiled_dti_edges, ax = ax[2])\n",
    "\n",
    "ax[0].set_xlabel('Scaled functional connectivity')\n",
    "ax[1].set_xlabel('Scaled MIND connectivity')\n",
    "ax[2].set_xlabel('Scaled DTI connectivity')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='graph-theory'></a>\n",
    "### <a id='toc1_1_5_'></a>[**3.**  Graph Theory](#toc0_)\n",
    "#### <a id='toc1_1_5_1_'></a>[From now, we will start working with some standard Graph Theory metrics.](#toc0_)\n",
    "\n",
    "\n",
    "The metrics that we will cover here are:\n",
    "- Density\n",
    "- Degree/Strength\n",
    "- Centrality: Eigenvector, Betweenness, Closeness, Degree, Page Rank\n",
    "- Path length\n",
    "- Modularity\n",
    "- Assortativity\n",
    "- Clustering coefficient\n",
    "\n",
    "##### <a id='toc1_1_5_1_1_'></a>[**Key point:**](#toc0_)\n",
    "Each of these metrics has its requisites for computation. For example, it is not possible to accurately compute closeness centrality and the average shortest path for fragmented networks (i.e., there are subsets of disconnected nodes). Therefore, keep that in mind when thinking about thresholding a matrix.\n",
    "\n",
    "Figure 2 provides a summary of some graph-theoretical metrics:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![GT.jpg](attachment:GT.jpg)\n",
    "Figure 2. Graph theoretical metrics. (A) A representation of a graph indicating centralities. (B) Representation of modularity and clustering coefficient. (C) The shortest path between vertices A and B. (D) The minimum spanning tree."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### <a id='toc1_1_5_1_2_'></a>[We will start by creating the graph and removing its self-loops (i.e., a connection of a node with itself). For illustrative purposes, we will focus on the group-level fMRI conenctivity graph.](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a graph\n",
    "centiled_fc = np.zeros(mean_fmri_connectivity.shape)\n",
    "centiled_fc[np.triu_indices(360, k = 1)] = centiled_fmri_edges\n",
    "centiled_fc += centiled_fc.T\n",
    "\n",
    "matrix = centiled_fc.copy()#mean_fmri_connectivity.copy()\n",
    "G = nx.from_numpy_array(matrix)\n",
    "\n",
    "# Removing self-loops\n",
    "G.remove_edges_from(list(nx.selfloop_edges(G)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### <a id='toc1_1_5_1_3_'></a>[Now, we compute the network's density.](#toc0_)\n",
    "\n",
    "\n",
    "<u>Definition</u>:\n",
    " A graph's density is the ratio between the number of edges and the total number of possible edges. \n",
    "\n",
    "Clearly, in all-to-all connected graphs, the density will be maximal (or 1), whereas for a graph without edges it will be 0. Here, just for the sake of demonstration, we will compute the density of different states of the network to show how density changes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(nx.density.__doc__)\n",
    "\n",
    "# Create graphs for comparison\n",
    "matrix2 = matrix.copy()\n",
    "matrix3 = matrix.copy()\n",
    "\n",
    "# Create sparser graphs\n",
    "matrix2[matrix2<=0.50] = 0\n",
    "matrix3[matrix3<=0.75] = 0\n",
    "\n",
    "st50G = nx.from_numpy_array(matrix2)\n",
    "st25G = nx.from_numpy_array(matrix3)\n",
    "\n",
    "st50G.remove_edges_from(list(nx.selfloop_edges(st50G)))\n",
    "st25G.remove_edges_from(list(nx.selfloop_edges(st25G)))\n",
    "\n",
    "# Compute densities\n",
    "alltoall = nx.density(G)\n",
    "st50 = nx.density(st50G)\n",
    "st25 = nx.density(st25G)\n",
    "\n",
    "names = ['All-To-All', '> 0.5', '> 0.75']\n",
    "values = [alltoall, st50, st25]\n",
    "\n",
    "dict(zip(names, values))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### <a id='toc1_1_5_1_4_'></a>[Now, we compute the nodal degree/strength.](#toc0_)\n",
    "\n",
    "<u>Definition</u>: In undirected weighted networks the node strength can be computed as the sum of the connectivity weights of the edges attached to each node. It is a primary metric to identify how important is a node in the graph. \n",
    "It is possible to apply a normalization (divide the weights by 1/N-1) to make the output value more intuitive. (Reference [3] pg. 119)  \n",
    "\n",
    "In degree computation, it is also common to compute the mean degree of the network, which is the sum of node degrees divides by the total number of nodes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Computation of nodal degree/strength\n",
    "#print(nx.degree.__doc__)\n",
    "\n",
    "strength = G.degree(weight='weight')\n",
    "strengths = {node: val for (node, val) in strength}\n",
    "nx.set_node_attributes(G, dict(strength), 'strength') # Add as nodal attribute\n",
    "\n",
    "# Normalized node strength values 1/N-1\n",
    "normstrenghts = {node: val * 1/(len(G.nodes)-1) for (node, val) in strength}\n",
    "nx.set_node_attributes(G, normstrenghts, 'strengthnorm') # Add as nodal attribute\n",
    "\n",
    "# Computing the mean degree of the network\n",
    "normstrengthlist = np.array([val * 1/(len(G.nodes)-1) for (node, val) in strength])\n",
    "mean_degree = np.sum(normstrengthlist)/len(G.nodes)\n",
    "\n",
    "import warnings # pymer4 needs to be updated to python3.1, so suppress warning to do with dataframe\n",
    "\n",
    "with warnings.catch_warnings():\n",
    "    warnings.filterwarnings(\"ignore\", category=UserWarning) # suppress warning about old version of distplot\n",
    "    sns.distplot(list(normstrengthlist), kde=True, norm_hist=False)\n",
    "plt.xlabel('Degree Values');\n",
    "plt.ylabel('Counts');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### <a id='toc1_1_5_1_5_'></a>[Next, we will compute the centralities!](#toc0_)\n",
    "\n",
    "Centralities are frequently used to understand which nodes occupy critical positions in the network.\n",
    "\n",
    "Remember: \n",
    "- Degree Centrality: The degree centrality for a node **v** is the fraction of nodes it is connected to. This metric is the same as node degree, so it will not be computed again. (NetworkX Documentation [4])\n",
    "\n",
    "- Closeness Centrality: In weighted graphs, the closeness centrality of a node __v__ is the reciprocal of the sum of the shortest weighted path distances from **v** to all *N-1* other nodes. An important thing to think about this metric is that a node with many low weight edges can have the same centrality as a node with only a few high-weighted edges. (NetworkX Documentation, Reference [3] - Chapter 5)\n",
    "\n",
    "- Betweenness Centrality: Betweenness centrality of a node **v** is the sum of the fraction of all-pairs shortest paths that pass through __v__. (NetworkX Documentation [4]) \n",
    "\n",
    "- Eigenvector Centrality: Eigenvector centrality computes the centrality for a node based on its neighbours' centrality. It takes into account not only quantity (e.g., degree centrality) but also quality. If a node is linked to many nodes that also display a high degree, that node will have high eigenvector centrality. (NetworkX Documentation)\n",
    "\n",
    "- Page Rank: PageRank computes a ranking of the nodes in the graph G based on the incoming links' structure. (NetworkX Documentation [4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "WCqIzQf0pdl9"
   },
   "outputs": [],
   "source": [
    "# Closeness centrality\n",
    "#print(nx.closeness_centrality.__doc__)\n",
    "\n",
    "# The function accepts a argument 'distance' that, in correlation-based networks, must be seen as the inverse ... \n",
    "# of the weight value. Thus, a high correlation value (e.g., 0.8) means a shorter distance (i.e., 0.2).\n",
    "G_distance_dict = {(e1, e2): 1 / abs(weight) for e1, e2, weight in G.edges(data='weight')}\n",
    "\n",
    "# Then add them as attributes to the graph edges\n",
    "nx.set_edge_attributes(G, G_distance_dict, 'distance')\n",
    "\n",
    "# Computation of Closeness Centrality\n",
    "closeness = nx.closeness_centrality(G, distance='distance')\n",
    "\n",
    "# Now we add the closeness centrality value as an attribute to the nodes\n",
    "nx.set_node_attributes(G, closeness, 'closecent')\n",
    "\n",
    "# Visualise  values directly\n",
    "#print(closeness)\n",
    "\n",
    "# Closeness Centrality Histogram\n",
    "with warnings.catch_warnings():\n",
    "    warnings.filterwarnings(\"ignore\", category=UserWarning) # suppress warning about old version of distplot\n",
    "    sns.distplot(list(closeness.values()), kde=True, norm_hist=False)\n",
    "plt.xlabel('Centrality Values');\n",
    "plt.ylabel('Counts');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "sl-xV5lKpdmG"
   },
   "outputs": [],
   "source": [
    "# Betweenness centrality:\n",
    "#print(nx.betweenness_centrality.__doc__)\n",
    "betweenness = nx.betweenness_centrality(G, weight='distance', normalized=True) \n",
    "                                                                \n",
    "# Now we add the it as an attribute to the nodes\n",
    "#nx.set_node_attributes(G, betweenness, 'bc')\n",
    "\n",
    "# Visualise  values directly\n",
    "#print(betweenness)\n",
    "\n",
    "# Betweenness centrality Histogram\n",
    "with warnings.catch_warnings():\n",
    "    warnings.filterwarnings(\"ignore\", category=UserWarning) # suppress warning about old version of distplot\n",
    "    sns.distplot(list(betweenness.values()), kde=False, norm_hist=False)\n",
    "plt.xlabel('Centrality Values');\n",
    "plt.ylabel('Counts');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "cUMdR0XGpdmK"
   },
   "outputs": [],
   "source": [
    "# Eigenvector centrality\n",
    "#print(nx.eigenvector_centrality.__doc__)\n",
    "eigen = nx.eigenvector_centrality(G, weight='weight')\n",
    "\n",
    "# Now we add the it as an attribute to the nodes\n",
    "nx.set_node_attributes(G, eigen, 'eigen')\n",
    "\n",
    "# Visualise  values directly\n",
    "#print(eigen)\n",
    "\n",
    "# Eigenvector centrality Histogram\n",
    "with warnings.catch_warnings():\n",
    "    warnings.filterwarnings(\"ignore\", category=UserWarning) # suppress warning about old version of distplot\n",
    "    sns.distplot(list(eigen.values()), kde=False, norm_hist=False)\n",
    "plt.xlabel('Centrality Values');\n",
    "plt.ylabel('Counts');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Page Rank\n",
    "#print(nx.pagerank.__doc__)\n",
    "pagerank = nx.pagerank(G, weight='weight')\n",
    "\n",
    "# Add as attribute to nodes\n",
    "nx.set_node_attributes(G, pagerank, 'pg')\n",
    "\n",
    "# Visualise values directly\n",
    "#print(pagerank)\n",
    "\n",
    "# Page Rank Histogram\n",
    "with warnings.catch_warnings():\n",
    "    warnings.filterwarnings(\"ignore\", category=UserWarning) # suppress warning about old version of distplot\n",
    "    sns.distplot(list(pagerank.values()), kde=False, norm_hist=False)\n",
    "plt.xlabel('Pagerank Values')\n",
    "plt.ylabel('Counts')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### <a id='toc1_1_5_1_6_'></a>[Now, let's move on to the Path Length!](#toc0_)\n",
    "\n",
    "- Shortest Path:  The shortest path (or distance) between two nodes in a graph. In a weighted graph it is obtained by the minimum sum of weights.\n",
    "\n",
    "- Average Path Length: It is a concept in network topology that is defined as the average number of steps along the shortest paths for all possible pairs of network nodes. It is a measure of the efficiency of information or mass transport on a network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "9yC3V9kPpdmT"
   },
   "outputs": [],
   "source": [
    "# Path Length\n",
    "#print(nx.shortest_path_length.__doc__)\n",
    "\n",
    "# This is a versatile version of the ones below in which one can define or not source and target. Remove the hashtag to use this version.\n",
    "#list(nx.shortest_path_length(G, weight='distance'))\n",
    "\n",
    "# This one can also be used if defining source and target: \n",
    "#print(nx.dijkstra_path_length.__doc__)\n",
    "nx.dijkstra_path_length(G, source=20, target=25, weight='distance')\n",
    "\n",
    "# Whereas this one is for all pairs. Remove the hashtag to use this version.\n",
    "#print(nx.all_pairs_dijkstra_path_length.__doc__)\n",
    "#list(nx.all_pairs_dijkstra_path_length(G, weight='distance'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Average Path Length or Characteristic Path Length\n",
    "#print(nx.average_shortest_path_length.__doc__)\n",
    "nx.average_shortest_path_length(G, weight='distance')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <a id='toc2_'></a>[Now, go back and redo this past section using graphs at different levels of sparsity. How do the results change?](#toc0_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <a id='toc3_'></a>[Explore the relationships between differnet node-level graph features. How do they compare to each other? What might this tell us?](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###### Code here  ########\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#########################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### <a id='toc3_1_1_1_1_'></a>[Now, modularity, assortativity, clustering coefficient and the minimum spanning tree!](#toc0_)\n",
    "\n",
    "- Modularity: Modularity compares the number of edges inside a cluster with the expected number of edges that one would find if the network was connected randomly but with the same number of nodes and node degrees. It is used to identify strongly connected subsets, i.e., modules or 'communities'. Here, we will use the Louvain algorithm, as recommended in Reference [3].\n",
    "\n",
    "- Assortativity: Assortativity measures the similarity of connections in the graph with respect to the node degree. (NetworkX)\n",
    "\n",
    "- Efficiency: The efficiency of a pair of nodes in a graph is the multiplicative inverse of the shortest path distance between the nodes.  More efficient -> shorter average path between nodes. (NetworkX documentation)\n",
    "\n",
    "- Clustering coefficient: a measure of the tendency for any two neighbours of a node to be directly connected. According to Networkx's documentation, weighted graphs' clustering coefficient is defined as the geometric average of the subgraph edge weights. (NetworkX, Reference [4])\n",
    "\n",
    "- Small-worldness: A small world network is characterized by a small average shortest path length, and a large clustering coefficient. Small-worldness is commonly measured with the coefficient sigma or omega. Both coefficients compare the average clustering coefficient and shortest path length of a given graph against the same quantities for an equivalent random or lattice graph. (NetworkX documentation)\n",
    " \n",
    "- Minimum Spanning Tree: it is the backbone of a network, i.e. the minimum set of edges necessary to ensure that paths exist between all nodes. A few main algorithms are used to build the spanning tree, being the Kruskal's algorithm the one used by NetworkX. Briefly, this algorithm ranks the distance of the edges, adds the ones with the smallest distance first, and by adding edge-by-edge, it checks if cycles are formed or not. The algorithm will not add an edge that results in the formation of a cycle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "VbxQWW7Dpdme"
   },
   "outputs": [],
   "source": [
    "# Modularity\n",
    "#print(community.best_partition.__doc__)\n",
    "#from community import best_partition\n",
    "part = community.best_partition(G, weight='weight')\n",
    "\n",
    "# Visualise values directly\n",
    "#print(part)\n",
    "\n",
    "# Check the number of communities\n",
    "set(part.values()).union()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "92lYxPrwpdmk"
   },
   "outputs": [],
   "source": [
    "#Assortativity\n",
    "#print(nx.degree_pearson_correlation_coefficient.__doc__)\n",
    "nx.degree_pearson_correlation_coefficient(G, weight='weight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Efficiency\n",
    "nx.global_efficiency(st50G)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Small worldness (takes ages)\n",
    "#nx.sigma(st50G, niter=100, nrand=10, seed=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "YzwmOX0Hpdmq"
   },
   "outputs": [],
   "source": [
    "# Clustering Coefficient\n",
    "#print(nx.clustering.__doc__)\n",
    "clustering = nx.clustering(G, weight='weight')\n",
    "\n",
    "# Add as attribute to nodes\n",
    "nx.set_node_attributes(G, clustering, 'cc')\n",
    "\n",
    "# Visualise values directly\n",
    "#print(clustering)\n",
    "\n",
    "# Clustering Coefficient Histogram\n",
    "with warnings.catch_warnings():\n",
    "    warnings.filterwarnings(\"ignore\", category=UserWarning) # suppress warning about old version of distplot\n",
    "    sns.distplot(list(clustering.values()), kde=False, norm_hist=False)\n",
    "plt.xlabel('Clustering Coefficient Values')\n",
    "plt.ylabel('Counts')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Minimum Spanning Tree\n",
    "GMST = nx.minimum_spanning_tree(G, weight='distance')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <a id='toc3_1_1_2_'></a>[Data Visualisation & Graph Theory](#toc0_)\n",
    "Under this section we we'll provide a few ideas of how to visualise and present your network."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, let's get some important attributes about brain area names and subnetworks. These will be used later for graphical visualisation!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "uaWDV3b7pdm6"
   },
   "outputs": [],
   "source": [
    "# Function to transform our list of brain areas into a dictionary\n",
    "def Convert(lst): \n",
    "    res_dct = {i : lst[i] for i in range(0, len(lst))} \n",
    "    return res_dct\n",
    "\n",
    "# Add brain areas as attribute of nodes\n",
    "nx.set_node_attributes(G, Convert(lineList), 'area')\n",
    "\n",
    "# Add node colors\n",
    "nx.set_node_attributes(G, Convert(colorlist), 'color')\n",
    "\n",
    "# Add subnetwork attribute\n",
    "nx.set_node_attributes(G, Convert(sublist), 'subnet')\n",
    "\n",
    "# Add node color numbers\n",
    "#nx.set_node_attributes(G, Convert(colornumbs), 'colornumb')\n",
    "nx.set_node_attributes(G, Convert(colornumbs), 'colornumb')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Pue9PiOcpdm-"
   },
   "source": [
    "Now we will create a standard spring network plot, but this could also be made circular by changing to *draw_circular*.\n",
    "\n",
    "We defined the edge widths to the power of 2 so that weak weights will have smaller widths."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard Network graph with nodes in proportion to Graph degrees\n",
    "plt.figure(figsize=(30,30))\n",
    "edgewidth = [ d['weight'] for (u,v,d) in G.edges(data=True)]\n",
    "pos = nx.spring_layout(G, scale=5)\n",
    "nx.draw(G, pos, with_labels=True, width=np.power(edgewidth, 2), edge_color='grey', node_size=normstrengthlist*20000, \n",
    "        labels=Convert(lineList), font_color='black', node_color=colornumbs/10, cmap=plt.cm.Spectral, alpha=0.7, font_size=9)\n",
    "#plt.savefig('network.jpeg')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <a id='toc4_'></a>[Obviously that is WAY too much information. Let's visualise the Minimum Spanning Tree instead.](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "plt.figure(figsize=(15,15))\n",
    "nx.draw(GMST, with_labels=True, alpha=0.7, labels=Convert(lineList), font_size=9)\n",
    "#nx.draw(GMST, with_labels=True, width=np.power(edgewidth, 0.5), edge_color='grey', node_size=normstrengthlist*200, \n",
    "#        labels=Convert(lineList), font_color='black', node_color=colornumbs/10, cmap=plt.cm.Spectral, alpha=0.7, font_size=9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "aO2VyMxUpdnD"
   },
   "source": [
    "* Detail! \n",
    "For the sake of a less overwhelming plot, we will work with the st50G graph for the CircosPlot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "nx.set_node_attributes(GMST, dict(GMST.degree(weight='weight')), 'strength')\n",
    "\n",
    "nx.set_node_attributes(GMST, Convert(lineList), 'area')\n",
    "\n",
    "nx.set_node_attributes(GMST, Convert(colorlist), 'color')\n",
    "\n",
    "nx.set_node_attributes(GMST, Convert(sublist), 'subnet')\n",
    "\n",
    "#edgecolors = {(e1, e2): int((weight+1)**3) for e1, e2, weight in st50G.edges(data='weight')}\n",
    "\n",
    "# Then add them as attributes to the graph\n",
    "#nx.set_edge_attributes(st50G, edgecolors, 'edgecolor')\n",
    "\n",
    "G_distance_dict2 = {(e1, e2): 1 / abs(weight) for e1, e2, weight in GMST.edges(data='weight')}\n",
    "\n",
    "# Then add them as attributes to the graph\n",
    "nx.set_edge_attributes(GMST, G_distance_dict2, 'distance')\n",
    "\n",
    "\n",
    "GMST_GRL = nx.relabel_nodes(GMST, {i: lineList[i] for i in range(len(lineList))})\n",
    "\n",
    "# CircosPlot\n",
    "fig, ax = plt.subplots(1,1,figsize = (30,30))\n",
    "circ = circos(GMST_GRL, edge_alpha_by=\"weight\", node_color_by=\"subnet\")#, figsize=(30,30))#, node_labels=True, node_label_layout='rotation', node_order='subnet',\n",
    "                 # edge_color='weight', edge_width='weight', node_color='subnet', node_label_color=True, fontsize=10, \n",
    "                 # nodeprops={\"radius\": 2}, group_legend=True, group_label_offset=5)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='Data Analysis on brain networks'></a>\n",
    "\n",
    "## <a id='toc4_1_'></a>[**4.** Have some fun with data analysis of brain networks!!](#toc0_)\n",
    "\n",
    "Here, spend about an hour explore relationships between different types of brain networks, and the relationship between different connectivity/network features and phenotypic features such as age and sex. Have some fune with it, be creative – I'll come around and talk to each of you."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Qs9E_TfzpdnX"
   },
   "source": [
    "If want meta-data on age, sex, etc, for correlations:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata = pd.read_csv('Simplified/metadata.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='references'></a>\n",
    "\n",
    "## <a id='toc4_2_'></a>[**5.** References](#toc0_)\n",
    "\n",
    "[1] Brown JA, Rudie JD, Bandrowski A, Van Horn JD, Bookheimer SY. The UCLA multimodal connectivity database: a web-based platform for brain connectivity matrix sharing and analysis. Front Neuroinform. 2012;6:28. doi: 10.3389/fninf.2012.00028.\n",
    "\n",
    "[2] Biswal BB, Mennes M, Zuo XN, Gohel S, Kelly C, Smith SM, et al. Toward discovery science of human brain function. Proc Natl Acad Sci U S A. 2010;107(10):4734-9. doi: 10.1073/pnas.0911855107.\n",
    "\n",
    "[3] Fornito A, Zalesky A, Bullmore E. Fundamentals of brain network analysis. 1st ed. San Diego: Academic Press; 2016.\n",
    "\n",
    "[4] Hagberg A, Swart P, S Chult D, editors. Exploring network structure, dynamics, and function using NetworkX. Proceedings of the 7th Python in Science conference (SciPy 2008); 2008 Aug 19-24; Pasadena, USA.\n",
    "\n",
    "[5] Bassett DS, Sporns O. Network neuroscience. Nat Neurosci. 2017;20(3):353. doi: 10.1038/nn.4502.\n",
    "\n",
    "[6] Santos FAN, Raposo EP, Coutinho-Filho MD, Copelli M, Stam CJ, Douw L. Topological phase transitions in functional brain networks. Phys Rev E. 2019;100(3-1):032414. doi: 10.1103/PhysRevE.100.032414."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='acknowledgements'></a>\n",
    "\n",
    "## <a id='toc4_3_'></a>[**6.** Acknowledgements](#toc0_)\n",
    "\n",
    "This tutorial is adapted from \"Centeno, E.G.Z., Moreni, G., Vriend, C. et al. A hands-on tutorial on network and topological neuroscience. Brain Struct Funct 227, 741–762 (2022).\"\n",
    "https://github.com/multinetlab-amsterdam/network_TDA_tutorial/tree/main."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "NetAnalysis.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
